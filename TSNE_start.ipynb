{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7079d7e8",
   "metadata": {},
   "source": [
    "# TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b282be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "from sklearn import preprocessing\n",
    "import torchvision.models as models\n",
    "#from torchsummary import summary\n",
    "import torch.nn as nn\n",
    "from src.models import WhaleDoModel\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from src.utils import *\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import torch\n",
    "#import imutils\n",
    "import tensorflow as tf\n",
    "from src.dataloader import WhaleDoDataset\n",
    "import pickle as pkl\n",
    "from pytorch_metric_learning import losses, miners\n",
    "from torch.utils.data import DataLoader\n",
    "from src.config import get_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5249f9c2",
   "metadata": {},
   "source": [
    "## Get train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27bc7583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>path</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>viewpoint</th>\n",
       "      <th>date</th>\n",
       "      <th>whale_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train0000</td>\n",
       "      <td>data/images/train0000.jpg</td>\n",
       "      <td>463</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-08-07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train0001</td>\n",
       "      <td>data/images/train0001.jpg</td>\n",
       "      <td>192</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-08-05</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train0002</td>\n",
       "      <td>data/images/train0002.jpg</td>\n",
       "      <td>625</td>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-08-07</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train0003</td>\n",
       "      <td>data/images/train0003.jpg</td>\n",
       "      <td>673</td>\n",
       "      <td>237</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-08-07</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train0004</td>\n",
       "      <td>data/images/train0004.jpg</td>\n",
       "      <td>461</td>\n",
       "      <td>166</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-08-10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    image_id                       path  height  width  viewpoint        date  \\\n",
       "0  train0000  data/images/train0000.jpg     463    150          0  2017-08-07   \n",
       "1  train0001  data/images/train0001.jpg     192     81          0  2019-08-05   \n",
       "2  train0002  data/images/train0002.jpg     625    183          0  2017-08-07   \n",
       "3  train0003  data/images/train0003.jpg     673    237          0  2017-08-07   \n",
       "4  train0004  data/images/train0004.jpg     461    166          0  2018-08-10   \n",
       "\n",
       "   whale_id  \n",
       "0         0  \n",
       "1         1  \n",
       "2         2  \n",
       "3         3  \n",
       "4         4  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = get_config()\n",
    "# load and parse the dataframe and get the label encoder as well\n",
    "train_df, label_encoder = load_csv_and_parse_dataframe(config['csv_name'], root_dir=config['root_dir'], drop_columns=['timestamp', 'encounter_id'])\n",
    "# get the average height and width of the dataset (rotate if viewpoint -1 or 1 (left / right))\n",
    "config['dataset']['height'], config['dataset']['width'] = get_avg_height_width(train_df)\n",
    "# get the mean and std of the dataset\n",
    "config['dataset']['mean'], config['dataset']['std'] = get_mean_and_std_of_dataset(train_df)\n",
    "# create the dataset objects\n",
    "train_data = WhaleDoDataset(train_df, config, mode='train')\n",
    "\n",
    "train_df = train_df.reset_index()\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7083ff36",
   "metadata": {},
   "source": [
    "## Get three samples from train_df\n",
    "In this part a row from train_df is randomly sampled (the anchor). If there are more whale_id's of this sample in train_df, the program will select randomly another row with the same whale_id (the positive). After that it will select a row which does not have this whale_id (the negative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84dcfac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell to get the samples from the train_df\n",
    "matched = False\n",
    "\n",
    "while matched == False:\n",
    "    random_sample = train_df.sample()\n",
    "    index = random_sample.index[0]\n",
    "    random_sample_id = int(random_sample['whale_id'])\n",
    "    random_sample_image_id = random_sample['image_id'].tolist()[0]\n",
    "    \n",
    "    positive_df = train_df.loc[train_df['whale_id']== random_sample_id]\n",
    "    positive_df = positive_df[positive_df.image_id != random_sample_image_id]\n",
    "    row_count = len(positive_df.head())\n",
    "\n",
    "    \n",
    "    if row_count > 1:\n",
    "        positive = positive_df.sample()\n",
    "        index_positive = positive.index[0]\n",
    "        negative =  train_df.loc[train_df['whale_id'] != random_sample_id].sample()\n",
    "        index_neg = negative.index[0]\n",
    "        matched = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ddb232a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>path</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>viewpoint</th>\n",
       "      <th>date</th>\n",
       "      <th>whale_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3760</th>\n",
       "      <td>train3760</td>\n",
       "      <td>data/images/train3760.jpg</td>\n",
       "      <td>450</td>\n",
       "      <td>126</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-08-09</td>\n",
       "      <td>529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id                       path  height  width  viewpoint  \\\n",
       "3760  train3760  data/images/train3760.jpg     450    126          0   \n",
       "\n",
       "            date  whale_id  \n",
       "3760  2018-08-09       529  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44bb27fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>path</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>viewpoint</th>\n",
       "      <th>date</th>\n",
       "      <th>whale_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5587</th>\n",
       "      <td>train5587</td>\n",
       "      <td>data/images/train5587.jpg</td>\n",
       "      <td>551</td>\n",
       "      <td>177</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-08-09</td>\n",
       "      <td>529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id                       path  height  width  viewpoint  \\\n",
       "5587  train5587  data/images/train5587.jpg     551    177          0   \n",
       "\n",
       "            date  whale_id  \n",
       "5587  2018-08-09       529  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8b807ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>path</th>\n",
       "      <th>height</th>\n",
       "      <th>width</th>\n",
       "      <th>viewpoint</th>\n",
       "      <th>date</th>\n",
       "      <th>whale_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4756</th>\n",
       "      <td>train4756</td>\n",
       "      <td>data/images/train4756.jpg</td>\n",
       "      <td>217</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-08-29</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       image_id                       path  height  width  viewpoint  \\\n",
       "4756  train4756  data/images/train4756.jpg     217    100          0   \n",
       "\n",
       "            date  whale_id  \n",
       "4756  2019-08-29        96  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negative.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50211aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indexes are:  3760 5587 4756\n"
     ]
    }
   ],
   "source": [
    "print('indexes are: ', index, index_positive, index_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bafda5",
   "metadata": {},
   "source": [
    "## Use __getitem__ and make a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c5e82ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the three items\n",
    "anchor_item = train_data.__getitem__(index)\n",
    "positive_item = train_data.__getitem__(index_positive)\n",
    "negative_item = train_data.__getitem__(index_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2b3718f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(anchor_item)\n",
    "# print(positive_item)\n",
    "# print(negative_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fac8ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /home/appuser/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "258f295d3b2b419c9ce5ad8aefff932b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/condaenv/lib/python3.9/site-packages/torch/nn/modules/lazy.py:175: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WhaleDoModel(\n",
       "  (backbone): BackBone(\n",
       "    (model): ResNet(\n",
       "      (conv1): Conv2d(4, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (fc): Linear(in_features=2048, out_features=512, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (projector): Projector(\n",
       "    (model): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=1024, bias=True)\n",
       "      (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Linear(in_features=1024, out_features=256, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from old code\n",
    "# init loss function and a miner. The miner samples for training samples\n",
    "loss_func = losses.TripletMarginLoss(margin=config['margin'])\n",
    "miner = miners.TripletMarginMiner(margin=config['margin'])\n",
    "\n",
    "device = config['device']\n",
    "# init model and optimizer\n",
    "model = WhaleDoModel(config)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'])\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924caf3f",
   "metadata": {},
   "source": [
    "## Make x_batch and y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ad904da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 561, 173])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "# make the three items into tensors and concatenate them into x_batch and y_batch\n",
    "anchor_x, anchor_y = anchor_item['image'], anchor_item['label']\n",
    "positive_x, positive_y = positive_item['image'], positive_item['label']\n",
    "negative_x, negative_y = negative_item['image'], negative_item['label']\n",
    "\n",
    "# torch.cat is to concatenate along existing dimensions\n",
    "# x_batch = torch.cat((anchor_x,positive_x,negative_x),1).to(config['device'])\n",
    "# stack is to create a new dimension (batches) for the batches. You could also manually create a singleton dimension\n",
    "# in the first position and then use torch.cat(..., 0)\n",
    "x_batch = torch.stack((anchor_x,positive_x,negative_x),0).to(config['device'])\n",
    "y_batch = torch.tensor((anchor_y,positive_y,negative_y)).to(config['device'])\n",
    "\n",
    "print(x_batch.shape)\n",
    "print(y_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb818104",
   "metadata": {},
   "source": [
    "## Get the Embeddings (ERROR)\n",
    "This part doesn't work. It expected 4 dimensional input and it received 3 dimensional. Since dataloader isn't used, I don't think the augmentations are done and it thus is 3 dimensional. (i think)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "923684c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the gradients to zero\n",
    "optimizer.zero_grad()\n",
    "\n",
    "#compute embeddings\n",
    "embeddings = model(x_batch)\n",
    "\n",
    "#mine for hard pairs\n",
    "# mined_pairs = miner(embeddings, y_batch)\n",
    "#compute loss\n",
    "\n",
    "# Not sure if you need the loss either \n",
    "\n",
    "# loss = loss_func(embeddings, y_batch)#, mined_pairs)\n",
    "\n",
    "\n",
    "# You don't need to calculate gradients or perform backprop cause you're just testing the model. use model.eval() or something similar.\n",
    "\n",
    "#calculate gradients\n",
    "# loss.backward()\n",
    "#update weights\n",
    "# optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2dc3ff",
   "metadata": {},
   "source": [
    "# Old Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8627b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config = get_config()\n",
    "# # load and parse the dataframe and get the label encoder as well\n",
    "# train_df, label_encoder = load_csv_and_parse_dataframe(config['csv_name'], root_dir=config['root_dir'], drop_columns=['timestamp', 'encounter_id'])\n",
    "# # get the average height and width of the dataset (rotate if viewpoint -1 or 1 (left / right))\n",
    "# config['dataset']['height'], config['dataset']['width'] = get_avg_height_width(train_df)\n",
    "# # get the mean and std of the dataset\n",
    "# config['dataset']['mean'], config['dataset']['std'] = get_mean_and_std_of_dataset(train_df)\n",
    "\n",
    "\n",
    "# # create the dataset objects\n",
    "# train_data = WhaleDoDataset(train_df, config, mode='train')\n",
    "\n",
    "# #### sample from train_df the right index and use it into get_item , two of same label ####\n",
    "# print(train_data.__getitem__(100)) ##### set __getitem__ to false #####\n",
    "\n",
    "# # create dataloaders\n",
    "# train_loader = DataLoader(train_data, config['batch_size'], shuffle=True)\n",
    "\n",
    "# # init loss function and a miner. The miner samples for training samples\n",
    "# loss_func = losses.TripletMarginLoss(margin=config['margin'])\n",
    "# miner = miners.TripletMarginMiner(margin=config['margin'])\n",
    "\n",
    "\n",
    "# device = config['device']\n",
    "# # init model and optimizer\n",
    "# model = WhaleDoModel(config)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=config['lr'])\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80096f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, batch in enumerate(train_loader):\n",
    "\n",
    "    \n",
    "# ##### MAKE THE TRIPKETS INTO X_BATCH #####\n",
    "#     #move tensors to device (gpu or cpu)\n",
    "#     x_batch, y_batch = batch['image'].to(config['device']), batch['label'].to(config['device'])\n",
    "\n",
    "#     #set the gradients to zero\n",
    "#     optimizer.zero_grad()\n",
    "\n",
    "#     #compute embeddings\n",
    "#     embeddings = model(x_batch)\n",
    "\n",
    "#     #mine for hard pairs\n",
    "#     # mined_pairs = miner(embeddings, y_batch)\n",
    "#     #compute loss\n",
    "#     loss = loss_func(embeddings, y_batch)#, mined_pairs)\n",
    "\n",
    "#     #calculate gradients\n",
    "#     loss.backward()\n",
    "#     #update weights\n",
    "#     optimizer.step()\n",
    "\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a6b50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, (x_batch, y_batch) in enumerate(train_loader):\n",
    "#     optimizer.zero_grad()\n",
    "#     embeddings = model(x_batch)\n",
    "#     loss = loss_func(embeddings, y_batch)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "\n",
    "#     print(i)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7abaeca9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729a0e55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e6603c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
